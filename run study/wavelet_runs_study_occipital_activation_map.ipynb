{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create activation/condition map-071720\n",
    "\n",
    "- Start with one subject, load in all the runs, mask, conditions labels (shift 2 TRs) , convert conditions from --binary format to multiclass formats \n",
    "- Use the packages ‘pyMVPA’ function ‘fmri_dataset' to create dataset\n",
    "- To reserve spatial information, function ‘ds.a.mapper.reverse’ was used to get back to the original form of the dataset.\n",
    "- Then multiply the brain with the mask to mask out irrelevant areas\n",
    "- Set condition labels \n",
    "- Choose the data/TR according to the conditions. All-voxel-wise\n",
    "- The take an average values according to each condition across all TRs. All-voxel-wise\n",
    "- Then find the condition shows maximum activation in each voxel\n",
    "- Then find all the voxels that each condition shows maximum values\n",
    "- Then re-assign values to each condition 1,2,3,4\n",
    "- Then save out the files into nifty format to view in Afni using function ‘ map2nifti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xueyingren/anaconda3/lib/python3.7/site-packages/mvpa2/base/hdf5.py:40: H5pyDeprecationWarning: The h5py.highlevel module is deprecated, code should import directly from h5py, e.g. 'from h5py import File'.\n",
      "  import h5py.highlevel  # >= 2.8.0, https://github.com/h5py/h5py/issues/1063\n",
      "/Users/xueyingren/anaconda3/lib/python3.7/site-packages/mvpa2/misc/surfing/volume_mask_dict.py:24: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n",
      "/Users/xueyingren/anaconda3/lib/python3.7/site-packages/mvpa2/testing/tools.py:82: DeprecationWarning: Importing from numpy.testing.decorators is deprecated since numpy 1.15.0, import from numpy.testing instead.\n",
      "  from numpy.testing.decorators import skipif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to load fast implementation of SMLR.  May be you forgotten to build it.  We will use much slower pure-Python version. Original exception was dlopen(/Users/xueyingren/anaconda3/lib/python3.7/site-packages/mvpa2/clfs/libsmlrc/smlrc.so, 6): image not found\n",
      " * Please note: warnings are printed only once, but underlying problem might occur many times *\n",
      "WARNING: SMLR: C implementation is not available. Using pure Python one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xueyingren/anaconda3/lib/python3.7/site-packages/mvpa2/datasets/sources/skl_data.py:32: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  argnames, varargs, varkw, defaults = inspect.getargspec(fx)\n",
      "<string>:57: DeprecationWarning: invalid escape sequence \\c\n",
      "/Users/xueyingren/anaconda3/lib/python3.7/site-packages/pywt/_utils.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to activate custom IPython completions due to 'function' object has no attribute 'when_type'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mvpa2.suite import *\n",
    "import os.path as op\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from pywt import wavedecn\n",
    "from scipy import stats\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from matplotlib.pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s1\n",
      "WARNING: Detected incorrect (nan) scl_ fields. Resetting to scl_slope=1.0 and scl_inter=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 1/8 [00:10<01:13, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:17<00:57,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [00:24<00:43,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [00:30<00:31,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [00:36<00:22,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [00:43<00:14,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [00:49<00:06,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:56<00:00,  7.05s/it]\n"
     ]
    }
   ],
   "source": [
    "subj_lst = [\"s1\",\"s2\",\"s3\",\"s5\",\"s6\",\"s7\",\"s8\",\"s10\"]\n",
    "\n",
    "condition_face_lst = []\n",
    "condition_obejcts_lst = []\n",
    "condition_place_lst = []\n",
    "condition_fruit_lst = []\n",
    "\n",
    "for subject in tqdm(subj_lst):\n",
    "\n",
    "    print(f\"subject={subject}\")\n",
    "    \n",
    "    run_lst = np.loadtxt(subject +'/'+'short_run_list.txt',dtype = str)\n",
    "    \n",
    "    bold_fname = []\n",
    "\n",
    "    for i in run_lst:\n",
    "        \n",
    "        all_runs = (subject+'/'+subject+'.nii/'+i+'.nii')\n",
    "        \n",
    "        bold_fname.append(all_runs)\n",
    "    \n",
    "    #mask = fmri_dataset(subject+'/occipital.nii') #load mask\n",
    "    mask = fmri_dataset(subject+'/occipital.nii') #load mask\n",
    "\n",
    "    conditions=loadmat(subject+'/conds_short_tlrc.mat')\n",
    "    conditions = conditions['conds_short_tlrc']\n",
    "    conditions_sh2 = shift(conditions,[0,2], cval=0) #shift by 2 TRs\n",
    "    \n",
    "    def convert_binary_to_multiclass(binary_conditions):\n",
    "        \"\"\"Convert binary representation into multiclass reprentation:\n",
    "        For example: convert [[1 1 1 1 0 0 0 0]\n",
    "                              [0 0 0 0 1 1 1 1]]\n",
    "        to [1 1 1 1 2 2 2 2]\"\"\"\n",
    "        x,y = np.where(binary_conditions)\n",
    "        conditions=np.zeros(binary_conditions.shape[1])\n",
    "        conditions[y]=x+1\n",
    "        return conditions\n",
    "\n",
    "    conditions_multi = convert_binary_to_multiclass(conditions_sh2)\n",
    "    \n",
    "    runs = np.arange(0,512)/32\n",
    "    \n",
    "    #ds = fmri_dataset (bold_fname, mask = subject+'/occipital.nii', targets = conditions_multi, chunks = runs)#mask = vt doesn't work here, because the error message 'array must be sequence' therefore, it has to be load with the file name\n",
    "    #print ds.summary()\n",
    "    ds = fmri_dataset (bold_fname, mask = subject+'/occipital.nii', targets = conditions_multi, chunks = runs)\n",
    "    \n",
    "    orig_data = ds.a.mapper.reverse(ds.samples)\n",
    "    orig_mask = mask.a.mapper.reverse(mask.samples)\n",
    "    #orig_mask\n",
    "    new_data = orig_mask * orig_data # dataset mutiply the mask ; shape(512, 64,64,42)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    # Then I label all the conditions\n",
    "    \n",
    "    face = conditions_multi == 1\n",
    "    objects = conditions_multi == 2\n",
    "    place = conditions_multi == 3\n",
    "    fruit = conditions_multi == 4\n",
    "    \n",
    "    face_all = new_data[face,:,:,:]\n",
    "    objects_all = new_data[objects,:,:,:]\n",
    "    place_all = new_data[place,:,:,:]\n",
    "    fruit_all = new_data[fruit,:,:,:]\n",
    "    \n",
    "    face_mean = np.mean(face_all, axis = 0)\n",
    "    objects_mean = np.mean(objects_all, axis = 0)\n",
    "    place_mean = np.mean(place_all,axis = 0)\n",
    "    fruit_mean =  np.mean(fruit_all, axis = 0)\n",
    "    \n",
    "    condition_max = np.argmax([face_mean, objects_mean, place_mean, fruit_mean],axis = 0)\n",
    "    \n",
    "    condition_face = (condition_max == 0)*orig_mask[0] # condition_max ==0 (the first element):face_mean; also includes the voxels values equal zero.  \n",
    "    condition_objects = (condition_max == 1) # no need to mutiply mask \n",
    "    condition_place = (condition_max == 2)\n",
    "    condition_fruit = (condition_max == 3)\n",
    "    \n",
    "    condition_face_lst.append(condition_face) # it is a mask tells you which voxels have maximum activation of faces\n",
    "    condition_obejcts_lst.append(condition_objects)#it is a mask tells you which voxels have maximum activation of objects\n",
    "    condition_place_lst.append(condition_place)\n",
    "    condition_fruit_lst.append(condition_fruit)\n",
    "    \n",
    "    new_mask = orig_mask.copy()[0]\n",
    "    #import pdb;pdb.set_trace()\n",
    "    new_mask [condition_face.astype(bool)] = 1\n",
    "    new_mask [condition_objects.astype(bool)] = 2\n",
    "    new_mask [condition_place.astype(bool)] = 3\n",
    "    new_mask [condition_fruit.astype(bool)] = 4\n",
    "    \n",
    "    fm = mask.a.mapper\n",
    "    mask.samples = fm.forward(new_mask.reshape(1,64,64,42))\n",
    "    map2nifti(mask).to_filename(f\"{subject}_condition_map_occipital.nii\")\n",
    "    #import pdb;pdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since above finding the condition with maximum activation in each voxel, which gets a label didn't reveal much information, now I am plotting each condition , which is the mean activation over all TRs, then plot the heatmap for each condition to see if there is some info there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s1\n",
      "WARNING: Detected incorrect (nan) scl_ fields. Resetting to scl_slope=1.0 and scl_inter=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 1/8 [00:05<00:41,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:11<00:35,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [00:18<00:31,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [00:24<00:23,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [00:30<00:17,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [00:35<00:11,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [00:40<00:05,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=s10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:45<00:00,  5.69s/it]\n"
     ]
    }
   ],
   "source": [
    "subj_lst = [\"s1\",\"s2\",\"s3\",\"s5\",\"s6\",\"s7\",\"s8\",\"s10\"]\n",
    "\n",
    "condition_face_lst = []\n",
    "condition_obejcts_lst = []\n",
    "condition_place_lst = []\n",
    "condition_fruit_lst = []\n",
    "\n",
    "for subject in tqdm(subj_lst):\n",
    "\n",
    "    print(f\"subject={subject}\")\n",
    "    \n",
    "    run_lst = np.loadtxt(subject +'/'+'short_run_list.txt',dtype = str)\n",
    "    \n",
    "    bold_fname = []\n",
    "\n",
    "    for i in run_lst:\n",
    "        \n",
    "        all_runs = (subject+'/'+subject+'.nii/'+i+'.nii')\n",
    "        \n",
    "        bold_fname.append(all_runs)\n",
    "    \n",
    "    #mask = fmri_dataset(subject+'/occipital.nii') #load mask\n",
    "    mask = fmri_dataset(subject+'/occipital.nii') #load mask\n",
    "\n",
    "    conditions=loadmat(subject+'/conds_short_tlrc.mat')\n",
    "    conditions = conditions['conds_short_tlrc']\n",
    "    conditions_sh2 = shift(conditions,[0,2], cval=0) #shift by 2 TRs\n",
    "    \n",
    "    def convert_binary_to_multiclass(binary_conditions):\n",
    "        \"\"\"Convert binary representation into multiclass reprentation:\n",
    "        For example: convert [[1 1 1 1 0 0 0 0]\n",
    "                              [0 0 0 0 1 1 1 1]]\n",
    "        to [1 1 1 1 2 2 2 2]\"\"\"\n",
    "        x,y = np.where(binary_conditions)\n",
    "        conditions=np.zeros(binary_conditions.shape[1])\n",
    "        conditions[y]=x+1\n",
    "        return conditions\n",
    "\n",
    "    conditions_multi = convert_binary_to_multiclass(conditions_sh2)\n",
    "    \n",
    "    runs = np.arange(0,512)/32\n",
    "    \n",
    "    #ds = fmri_dataset (bold_fname, mask = subject+'/occipital.nii', targets = conditions_multi, chunks = runs)#mask = vt doesn't work here, because the error message 'array must be sequence' therefore, it has to be load with the file name\n",
    "    #print ds.summary()\n",
    "    ds = fmri_dataset (bold_fname, mask = subject+'/occipital.nii', targets = conditions_multi, chunks = runs)\n",
    "    \n",
    "    orig_data = ds.a.mapper.reverse(ds.samples)\n",
    "    orig_mask = mask.a.mapper.reverse(mask.samples)\n",
    "    #orig_mask\n",
    "    new_data = orig_mask * orig_data # dataset mutiply the mask ; shape(512, 64,64,42)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    # Then I label all the conditions\n",
    "    \n",
    "    face = conditions_multi == 1\n",
    "    objects = conditions_multi == 2\n",
    "    place = conditions_multi == 3\n",
    "    fruit = conditions_multi == 4\n",
    "    \n",
    "    face_all = new_data[face,:,:,:]# take out all TRs for each condition\n",
    "    objects_all = new_data[objects,:,:,:]\n",
    "    place_all = new_data[place,:,:,:]\n",
    "    fruit_all = new_data[fruit,:,:,:]\n",
    "    \n",
    "    face_mean = np.mean(face_all, axis = 0) # take average across all TRs\n",
    "    objects_mean = np.mean(objects_all, axis = 0)\n",
    "    place_mean = np.mean(place_all,axis = 0)\n",
    "    fruit_mean =  np.mean(fruit_all, axis = 0)\n",
    "    \n",
    "    #condition_max = np.argmax([face_mean, objects_mean, place_mean, fruit_mean],axis = 0)\n",
    "    \n",
    "    #condition_face = (condition_max == 0)*orig_mask[0] # condition_max ==0 (the first element):face_mean; also includes the voxels values equal zero.  \n",
    "    #condition_objects = (condition_max == 1) # no need to mutiply mask \n",
    "    #condition_place = (condition_max == 2)\n",
    "    #condition_fruit = (condition_max == 3)\n",
    "    \n",
    "    #condition_face_lst.append(condition_face) # it is a mask tells you which voxels have maximum activation of faces\n",
    "    #condition_obejcts_lst.append(condition_objects)#it is a mask tells you which voxels have maximum activation of objects\n",
    "    #condition_place_lst.append(condition_place)\n",
    "    #condition_fruit_lst.append(condition_fruit)\n",
    "    \n",
    "    condition_face_lst.append(face_mean) # it is a mask tells you which voxels have maximum activation of faces\n",
    "    condition_obejcts_lst.append(objects_mean)#it is a mask tells you which voxels have maximum activation of objects\n",
    "    condition_place_lst.append(place_mean)\n",
    "    condition_fruit_lst.append(fruit_mean)\n",
    "    \n",
    "    \n",
    "    fm = mask.a.mapper\n",
    "    mask.samples = fm.forward(face_mean.reshape(1,64,64,42))\n",
    "    map2nifti(mask).to_filename(f\"{subject}_condition_map_face_occipital.nii\")\n",
    "    \n",
    "    fm = mask.a.mapper\n",
    "    mask.samples = fm.forward(objects_mean.reshape(1,64,64,42))\n",
    "    map2nifti(mask).to_filename(f\"{subject}_condition_map_object_occipital.nii\")\n",
    "    #import pdb;pdb.set_trace()\n",
    "    \n",
    "    fm = mask.a.mapper\n",
    "    mask.samples = fm.forward(place_mean.reshape(1,64,64,42))\n",
    "    map2nifti(mask).to_filename(f\"{subject}_condition_map_place_occipital.nii\")\n",
    "    \n",
    "    fm = mask.a.mapper\n",
    "    mask.samples = fm.forward(fruit_mean.reshape(1,64,64,42))\n",
    "    map2nifti(mask).to_filename(f\"{subject}_condition_map_fruit_occipital.nii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
